{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0373a7d1-7020-44a9-bd7f-6d4911eb747b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a44bd6-b7cf-49fe-a6ad-8dd8b7adf3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 07:01:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Creating a SparkSession\n",
    "spark = SparkSession.builder.appName(\"AirlinesData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d890c8-f47b-43b7-ae31-08052bd89afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Loading the passengers data from a csv file in a gcs bucket\n",
    "passengers_df = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", True)\\\n",
    "                            .option(\"inferschema\", True)\\\n",
    "                            .option(\"mode\", \"PERMISSIVE\")\\\n",
    "                            .load(\"gs://bucket_path/passengers_dirty.csv\")\n",
    "\n",
    "# Loading the flight bookings data from a csv file in a gcs bucket\n",
    "airlines_df = spark.read.format(\"csv\")\\\n",
    "                        .option(\"header\", True)\\\n",
    "                        .option(\"inferschema\", True)\\\n",
    "                        .option(\"mode\", \"PERMISSIVE\")\\\n",
    "                        .load(\"gs://bucket_path/flight_bookings_dirty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936cabe1-1869-4694-bac6-722b2f2921ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------------+\n",
      "|Passenger_ID|Passenger_Name|          Class|\n",
      "+------------+--------------+---------------+\n",
      "|           1|    Odika Rama|Premium Economy|\n",
      "|           2|      Ryan Jha|       Business|\n",
      "|           3|    Megha Keer|        Economy|\n",
      "|           4| Zaitra Minhas|Premium Economy|\n",
      "|           5|     Aarav Ram|       Business|\n",
      "+------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passengers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d9198c-ade3-410d-88bc-b41f23f29e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------+-------------------+-------------------+---------+-----------+-----+------------+\n",
      "|Booking_ID|       Booking_Date|  Airline|        Travel_Date|       Arrival_Date|   Source|Destination|Price|Passenger_ID|\n",
      "+----------+-------------------+---------+-------------------+-------------------+---------+-----------+-----+------------+\n",
      "|         1|2021-01-09 00:00:00| SpiceJet|2021-01-29 14:49:00|2021-01-29 19:47:00|     Pune|      Delhi| 7996|           1|\n",
      "|         2|2021-04-27 00:00:00|Akasa Air|2021-04-28 09:08:00|2021-04-28 13:16:00|  Lucknow|      Delhi| 9011|           1|\n",
      "|         3|2022-10-18 00:00:00|Akasa Air|2022-11-16 11:19:00|2022-11-16 14:16:00|Hyderabad|      Patna|10179|           1|\n",
      "|         4|2020-12-07 00:00:00|   TruJet|2020-12-14 19:19:00|2020-12-15 01:54:00|    Delhi|    Chennai| 7452|           2|\n",
      "|         5|2021-04-02 00:00:00| SpiceJet|2021-04-26 21:44:00|2021-04-27 03:21:00|    Patna|     Indore| 9741|           2|\n",
      "+----------+-------------------+---------+-------------------+-------------------+---------+-----------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35bed74b-a219-4de2-a848-d619813c9d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Passenger_ID: integer (nullable = true)\n",
      " |-- Passenger_Name: string (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Booking_ID: integer (nullable = true)\n",
      " |-- Booking_Date: string (nullable = true)\n",
      " |-- Airline: string (nullable = true)\n",
      " |-- Travel_Date: timestamp (nullable = true)\n",
      " |-- Arrival_Date: timestamp (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Destination: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Passenger_ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema for passengers data\n",
    "passengers_df.printSchema()\n",
    "\n",
    "# Print the schema of the flight bookings data\n",
    "airlines_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb662d20-2763-4ecb-8e23-5d137f899860",
   "metadata": {},
   "source": [
    "## Checking for null values in both dataframes and fixing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ef966f-e4e7-497e-82bd-32d5c96346b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----+\n",
      "|Passenger_ID|Passenger_Name|Class|\n",
      "+------------+--------------+-----+\n",
      "|           0|             0|    0|\n",
      "+------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for the null values in each column of passengers_df\n",
    "passengers_null_count = passengers_df\\\n",
    "                    .select(\n",
    "                            [sum(col(c).isNull().cast(\"int\")).alias(c) for c in passengers_df.columns]\n",
    "                    )\n",
    "passengers_null_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb4b75f-2085-488c-b9b8-77c9ace3294b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "|Booking_ID|Booking_Date|Airline|Travel_Date|Arrival_Date|Source|Destination|Price|Passenger_ID|\n",
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "|         0|          28|      0|         33|          33|     0|          0|    0|           0|\n",
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values in each column of airlines_df\n",
    "airlines_null_count = airlines_df\\\n",
    "                    .select(\n",
    "                            [sum(col(c).isNull().cast(\"int\")).alias(c) for c in airlines_df.columns]\n",
    "                    )\n",
    "airlines_null_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b5f85c-64d2-47a6-ace1-d00a0e5f8950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "|Booking_ID|Booking_Date|Airline|Travel_Date|Arrival_Date|Source|Destination|Price|Passenger_ID|\n",
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "|         0|           0|      0|          0|           0|     0|          0|    0|           0|\n",
      "+----------+------------+-------+-----------+------------+------+-----------+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Dropping rows with any null values in any of columns in airlines_df\n",
    "airlines_df = airlines_df.dropna(how=\"any\")\n",
    "\n",
    "# Rechecking for null values after dropping\n",
    "airlines_null_count = airlines_df\\\n",
    "                    .select(\n",
    "                        [sum(col(c).isNull().cast(\"int\")).alias(c) for c in airlines_df.columns]\n",
    "                    )\n",
    "airlines_null_count.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f115f-3b26-47bd-b24a-6ba11ede9d3a",
   "metadata": {},
   "source": [
    "## Fixing the format of Booking_Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a033d67a-c7ea-44bf-ae47-f8d8af6398cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Booking_Date|\n",
      "+------------+\n",
      "|  2021-01-09|\n",
      "|  2021-04-27|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dealing with the Booking_Date column\n",
    "flight_booking_date = airlines_df\\\n",
    "                            .withColumn(\n",
    "                                        \"Booking_Date\",\n",
    "                                        when(col(\"Booking_Date\").contains(\" \"), split(col(\"Booking_Date\"), \" \")[0])\n",
    "                                        .otherwise(col(\"Booking_Date\"))\n",
    "                            ).withColumn(\n",
    "                                        \"Booking_Date\",\n",
    "                                        coalesce(\n",
    "                                            to_date(\"Booking_Date\", \"yyyy-MM-dd\"),\n",
    "                                            to_date(\"Booking_Date\", \"dd/MM/yyyy\")\n",
    "                                        )\n",
    "                            )\n",
    "                                \n",
    "flight_booking_date.select(\"Booking_Date\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e468f-a96d-4ec1-9bf5-75bcd51d413b",
   "metadata": {},
   "source": [
    "## Extracting travel and arrival times from the Travel_Date and Arrival_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e993d9a4-b15e-49d7-a476-81f0f9c67ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+-------------------+-------------------+------+-----------+-----+------------+-------------+--------------+------------+-------------+\n",
      "|Booking_ID|Booking_Date| Airline|        Travel_Date|       Arrival_Date|Source|Destination|Price|Passenger_ID|Take_Off_Time|Traveling_Date|Landing_time|Arriving_Date|\n",
      "+----------+------------+--------+-------------------+-------------------+------+-----------+-----+------------+-------------+--------------+------------+-------------+\n",
      "|         1|  2021-01-09|SpiceJet|2021-01-29 14:49:00|2021-01-29 19:47:00|  Pune|      Delhi| 7996|           1|     14:49:00|    2021-01-29|    19:47:00|   2021-01-29|\n",
      "+----------+------------+--------+-------------------+-------------------+------+-----------+-----+------------+-------------+--------------+------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating seperate time and date columns\n",
    "flight_travel_arrival_time_df = flight_booking_date\\\n",
    "                                    .withColumn(\"Take_Off_Time\", date_format(\"Travel_Date\", \"HH:mm:ss\"))\\\n",
    "                                    .withColumn(\"Traveling_Date\", to_date(\"Travel_Date\", \"yyyy-MM-dd\"))\\\n",
    "                                    .withColumn(\"Landing_time\", date_format(\"Arrival_Date\", \"HH:mm:ss\"))\\\n",
    "                                    .withColumn(\"Arriving_Date\", to_date(\"Travel_Date\", \"yyyy-MM-dd\"))\n",
    "flight_travel_arrival_time_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49433521-1af7-4f90-b1b4-c1650e092a96",
   "metadata": {},
   "source": [
    "## Calculating the flight duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa31109-b81c-4041-8002-aa6048eb36ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|Booking_ID|Booking_Date| Airline|Source|Destination|Traveling_Date|Take_Off_Time|Arriving_Date|Landing_Time|Duration_in_hours|Price|Passenger_ID|\n",
      "+----------+------------+--------+------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|         1|  2021-01-09|SpiceJet|  Pune|      Delhi|    2021-01-29|     14:49:00|   2021-01-29|    19:47:00|              5.0| 7996|           1|\n",
      "+----------+------------+--------+------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Will calculate the flight duration and then select relevant columns\n",
    "flight_duration_df = flight_travel_arrival_time_df\\\n",
    "                        .withColumn(\n",
    "                                \"Duration_in_hours\",\n",
    "                                round((unix_timestamp(\"Arrival_Date\") - unix_timestamp(\"Travel_Date\"))/3600)\n",
    "                        ).selectExpr(\n",
    "                                \"Booking_ID\", \"Booking_Date\", \"Airline\", \"Source\", \"Destination\",\n",
    "                                \"Traveling_Date\", \"Take_Off_Time\", \"Arriving_Date\", \"Landing_Time\",\n",
    "                                \"Duration_in_hours\", \"Price\", \"Passenger_ID\"\n",
    "                        )\n",
    "flight_duration_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fd400-459f-4b6f-8390-b35a95440cb4",
   "metadata": {},
   "source": [
    "## Fixing the airline column which has corrputed/bad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c667e30d-0e04-4631-b18e-063b361f1f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering out the airlines with names less than or equal to 3 characters\n",
    "airline_names_df = flight_duration_df.filter(length(col(\"Airline\")) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f55185d-d187-4544-9c85-29dee938103a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad records in Airline column : ['Spic', 'Vistar', 'AirAsia Indi', 'Star Ai', 'Go Fir', 'Akasa ', 'AirAsia ', 'Akasa Ai', 'Star A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fetching incorrect airline names into a list\n",
    "wrong_unique_airlines = airline_names_df.filter(\n",
    "    \"Airline NOT IN ('Air India', 'IndiGo', 'SpiceJet', 'Go First', 'Vistara', 'AirAsia India', 'Alliance Air', 'Star Air', 'TruJet', 'Akasa Air')\"\n",
    ").select(\"Airline\").distinct()\n",
    "\n",
    "wrong_unique_airlines_list = [row[\"Airline\"] for row in wrong_unique_airlines.collect()] \n",
    "print(f\"Bad records in Airline column : {wrong_unique_airlines_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9748cfbb-b862-47b1-a617-bbd3e84425d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|Booking_ID|Booking_Date|  Airline|   Source|Destination|Traveling_Date|Take_Off_Time|Arriving_Date|Landing_Time|Duration_in_hours|Price|Passenger_ID|\n",
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|         1|  2021-01-09| SpiceJet|     Pune|      Delhi|    2021-01-29|     14:49:00|   2021-01-29|    19:47:00|              5.0| 7996|           1|\n",
      "|         2|  2021-04-27|Akasa Air|  Lucknow|      Delhi|    2021-04-28|     09:08:00|   2021-04-28|    13:16:00|              4.0| 9011|           1|\n",
      "|         3|  2022-10-18|Akasa Air|Hyderabad|      Patna|    2022-11-16|     11:19:00|   2022-11-16|    14:16:00|              3.0|10179|           1|\n",
      "|         4|  2020-12-07|   TruJet|    Delhi|    Chennai|    2020-12-14|     19:19:00|   2020-12-14|    01:54:00|              7.0| 7452|           2|\n",
      "|         5|  2021-04-02| SpiceJet|    Patna|     Indore|    2021-04-26|     21:44:00|   2021-04-26|    03:21:00|              6.0| 9741|           2|\n",
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Defining a mapping for valid airline names\n",
    "airline_mapping = {\n",
    "    \"AirAsia \": \"AirAsia India\",\n",
    "    \"Spic\": \"SpiceJet\",\n",
    "    \"Vistar\": \"Vistara\",\n",
    "    \"Star Ai\": \"Star Air\",\n",
    "    \"Akasa Ai\": \"Akasa Air\",\n",
    "    \"Star A\": \"Star Air\",\n",
    "    \"Go Fir\": \"Go First\",\n",
    "    \"Akasa \": \"Akasa Air\",\n",
    "    \"AirAsia Indi\": \"AirAsia India\"\n",
    "}\n",
    "\n",
    "# Broadcasting the mapping dictionary\n",
    "airline_map_broadcast = spark.sparkContext.broadcast(airline_mapping)\n",
    "\n",
    "# Defining a function to fix airline column\n",
    "def fix_airline_name(airline_name) :\n",
    "    return airline_map_broadcast.value.get(airline_name, airline_name)\n",
    "\n",
    "# Creating a udf for applying the mapping\n",
    "fix_airline_udf = udf(fix_airline_name, StringType())\n",
    "\n",
    "# Now Applying the udf to clean the airline column\n",
    "cleaned_airline_df = airline_names_df.withColumn(\"Airline\", fix_airline_udf(col(\"Airline\")))\n",
    "cleaned_airline_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c474906-983f-471e-89d4-a8d002714350",
   "metadata": {},
   "source": [
    "## Correct negative price values to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7bdd5b5-8986-428b-bce7-8e4f35841847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|Booking_ID|Booking_Date|  Airline|   Source|Destination|Traveling_Date|Take_Off_Time|Arriving_Date|Landing_Time|Duration_in_hours|Price|Passenger_ID|\n",
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "|         1|  2021-01-09| SpiceJet|     Pune|      Delhi|    2021-01-29|     14:49:00|   2021-01-29|    19:47:00|              5.0| 7996|           1|\n",
      "|         2|  2021-04-27|Akasa Air|  Lucknow|      Delhi|    2021-04-28|     09:08:00|   2021-04-28|    13:16:00|              4.0| 9011|           1|\n",
      "|         3|  2022-10-18|Akasa Air|Hyderabad|      Patna|    2022-11-16|     11:19:00|   2022-11-16|    14:16:00|              3.0|10179|           1|\n",
      "|         4|  2020-12-07|   TruJet|    Delhi|    Chennai|    2020-12-14|     19:19:00|   2020-12-14|    01:54:00|              7.0| 7452|           2|\n",
      "|         5|  2021-04-02| SpiceJet|    Patna|     Indore|    2021-04-26|     21:44:00|   2021-04-26|    03:21:00|              6.0| 9741|           2|\n",
      "+----------+------------+---------+---------+-----------+--------------+-------------+-------------+------------+-----------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Dealing with price column by correcting the negative values in price column\n",
    "price_df = cleaned_airline_df.withColumn(\"Price\", abs(col(\"Price\")))\n",
    "price_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb2582-fcf8-4159-87e4-d756a7b93ae1",
   "metadata": {},
   "source": [
    "## Joining the passengers_df and price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289e96cf-33c1-4dba-a166-6d32f03ee515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------------+----------+------------+---------+-------+-----------+--------------+-------------+-------------+------------+-----------------+-----+\n",
      "|Passenger_ID|Passenger_Name|          Class|Booking_ID|Booking_Date|  Airline| Source|Destination|Traveling_Date|Take_Off_Time|Arriving_Date|Landing_Time|Duration_in_hours|Price|\n",
      "+------------+--------------+---------------+----------+------------+---------+-------+-----------+--------------+-------------+-------------+------------+-----------------+-----+\n",
      "|           1|    Odika Rama|Premium Economy|         1|  2021-01-09| SpiceJet|   Pune|      Delhi|    2021-01-29|     14:49:00|   2021-01-29|    19:47:00|              5.0| 7996|\n",
      "|           1|    Odika Rama|Premium Economy|         2|  2021-04-27|Akasa Air|Lucknow|      Delhi|    2021-04-28|     09:08:00|   2021-04-28|    13:16:00|              4.0| 9011|\n",
      "+------------+--------------+---------------+----------+------------+---------+-------+-----------+--------------+-------------+-------------+------------+-----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Using join\n",
    "final_joined_df = passengers_df.join(price_df, [\"Passenger_ID\"], how=\"inner\")\n",
    "final_joined_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172abad3-dd97-4e32-9182-b535ce049444",
   "metadata": {},
   "source": [
    "## Setting up the BigQuery details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b85ff5-c7b4-4fe8-bb10-b2aef344df0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the data into the BigQuery table synthetic-nova-438808-k6.Airlines_dataset.airlines_data\n"
     ]
    }
   ],
   "source": [
    "# Define the BigQuery table name\n",
    "table_name = \"your-project-id.dataset-id.airlines_data\"\n",
    "\n",
    "# Define the GCS bucket for temporary storage\n",
    "temp_bucket = \"gs://path_to_temp_folder/bq_temp_folder\"\n",
    "\n",
    "# Writing the DataFrame to BigQuery\n",
    "try :\n",
    "    final_joined_df.write \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .option(\"table\", table_name) \\\n",
    "            .option(\"writeDisposition\", \"WRITE_APPEND\") \\\n",
    "            .option(\"temporaryGcsBucket\", temp_bucket) \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "    print(f\"Successfully loaded the data into the BigQuery table {table_name}\")\n",
    "except Exception as e :\n",
    "    print(f\"Error while loading the dataframe : {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a93aa-459e-470f-8473-71e37b9c3df7",
   "metadata": {},
   "source": [
    "## Stopping the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beaaed6a-8c99-4ece-b82b-94564545654f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session stopped successfully.\n"
     ]
    }
   ],
   "source": [
    "# Stop the Spark session to release resources\n",
    "if spark:\n",
    "    spark.stop()\n",
    "    print(\"Spark session stopped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb963db5-d05e-4e2c-beda-499a64a415c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
